{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carol/anaconda3/envs/anotherone/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {\"path\": \"/home/carol/NaroNet-main/NaroNet-main/EXP2/\", \"PCL_embedding_dimensions\": 256, \"PCL_batch_size\": 160, \"PCL_epochs\": 300, \"PCL_patch_size\": 32, \"PCL_alpha_L\": 1.3, \"PCL_ZscoreNormalization\": True,\n",
    "\"PCL_width_CNN\": 2, \"PCL_depth_CNN\": 50, \"experiment_Label\": [\"Response\"], \"num_samples_architecture_search\": 100, \"epochs\": 20, \"epoch\": 0, \"lr_decay_factor\": 0.5, \"lr_decay_step_size\": 12, \"weight_decay\": 0.01,\n",
    "\"batch_size\": 6, \"lr\": 0.001, \"useOptimizer\": \"ADAM\", \"context_size\": 15, \"num_classes\": 3, \"MultiClass_Classification\": 1, \"showHowNetworkIsTraining\": True, \"visualizeClusters\": True, \"learnSupvsdClust\": True, \n",
    "\"recalculate\": False, \"folds\": 13, \"device\": \"cuda\", \"normalizeFeats\": False, \"normalizeCells\": False, \"Batch_Normalization\": True, \"normalizePercentile\": False, \"dataAugmentationPerc\": 0.0001, \"hiddens\": 44,\n",
    "\"clusters1\": 10, \"clusters2\": 9, \"clusters3\": 7, \"LSTM\": False, \"GLORE\": False, \"Phenotypes\": True, \"DeepSimple\": False, \"isAttentionLayer\": False, \"ClusteringOrAttention\": True, \"1cell1cluster\": False,\n",
    "\"dropoutRate\": 0.2, \"AttntnSparsenss\": False, \"attntnThreshold\": 0, \"GraphConvolution\": \"ResNet\", \"n-hops\": 3, \"modeltype\": \"SAGE\", \"ObjectiveCluster\": True, \"ReadoutFunction\": False,\n",
    "\"NearestNeighborClassification\": False, \"NearestNeighborClassification_Lambda0\": 1, \"NearestNeighborClassification_Lambda1\": 1, \"NearestNeighborClassification_Lambda2\": 1, \"KinNearestNeighbors\": 5,\n",
    "\"pearsonCoeffSUP\": False, \"pearsonCoeffUNSUP\": False, \"orthoColor\": True, \"orthoColor_Lambda0\": 0.1, \"orthoColor_Lambda1\": 1e-05, \"ortho\": False, \"ortho_Lambda0\": 0.1, \"ortho_Lambda1\": 0, \"ortho_Lambda2\": 0,\n",
    "\"min_Cell_entropy\": True, \"min_Cell_entropy_Lambda0\": 1, \"min_Cell_entropy_Lambda1\": 0.0001, \"min_Cell_entropy_Lambda2\": 0.01, \"MinCut\": True, \"MinCut_Lambda0\": 0, \"MinCut_Lambda1\": 0.1, \"MinCut_Lambda2\": 0.1,\n",
    "\"F-test\": False, \"Max_Pat_Entropy\": False, \"Max_Pat_Entropy_Lambda0\": 0.0001, \"Max_Pat_Entropy_Lambda1\": 0.1, \"Max_Pat_Entropy_Lambda2\": 0.1, \"UnsupContrast\": False, \"UnsupContrast_Lambda0\": 0,\n",
    "\"UnsupContrast_Lambda1\": 0, \"UnsupContrast_Lambda2\": 0, \"Lasso_Feat_Selection\": False, \"Lasso_Feat_Selection_Lambda0\": 0.1, \"SupervisedLearning_Lambda0\": 1, \"SupervisedLearning_Lambda1\": 1, \n",
    "\"SupervisedLearning_Lambda2\": 1, \"SupervisedLearning_Lambda3\": 1, \"SupervisedLearning\": True}\n",
    "\n",
    "params2 = {'path': '/home/carol/NaroNet-main/NaroNet-main/EXP2/', 'PCL_embedding_dimensions': 256, 'PCL_batch_size': 160, 'PCL_epochs': 300, 'PCL_patch_size': 32,\n",
    "'PCL_alpha_L': 1.3, 'PCL_ZscoreNormalization': True, 'PCL_width_CNN': 2, 'PCL_depth_CNN': 50, 'experiment_Label': ['Response'], 'num_samples_architecture_search': 50,\n",
    "'epochs': 10, 'epoch': 0, 'lr_decay_factor': 0.5, 'lr_decay_step_size': 12, 'weight_decay': 0.01, 'batch_size': 6, 'lr': 0.00001, 'useOptimizer': 'ADAM', 'context_size': 15,\n",
    "'num_classes': 3, 'MultiClass_Classification': 1, 'showHowNetworkIsTraining': False, 'visualizeClusters': True, 'learnSupvsdClust': True, 'recalculate': False, 'folds': 13,\n",
    "'device': 'cuda', 'normalizeFeats': False, 'normalizeCells': False, 'Batch_Normalization': True, 'normalizePercentile': False, 'dataAugmentationPerc': 0.0001, 'hiddens': 44,\n",
    "'clusters1': 10, 'clusters2': 9, 'clusters3': 7, 'LSTM': False, 'GLORE': False, 'Phenotypes': True, 'DeepSimple': False, 'isAttentionLayer': False,\n",
    "'ClusteringOrAttention': True, '1cell1cluster': False, 'dropoutRate': 0.2, 'AttntnSparsenss': False, 'attntnThreshold': 0, 'GraphConvolution': 'ResNet', 'n-hops': 3, \n",
    "'modeltype': 'SAGE', 'ObjectiveCluster': True, 'ReadoutFunction': False, 'NearestNeighborClassification': False, 'NearestNeighborClassification_Lambda0': 1, \n",
    "'NearestNeighborClassification_Lambda1': 1, 'NearestNeighborClassification_Lambda2': 1, 'KinNearestNeighbors': 5, 'pearsonCoeffSUP': False, 'pearsonCoeffUNSUP': False,\n",
    "'orthoColor': True, 'orthoColor_Lambda0': 0.1, 'orthoColor_Lambda1': 1e-05, 'ortho': False, 'ortho_Lambda0': 0.1, 'ortho_Lambda1': 0, 'ortho_Lambda2': 0,\n",
    "'min_Cell_entropy': True, 'min_Cell_entropy_Lambda0': 1, 'min_Cell_entropy_Lambda1': 0.0001, 'min_Cell_entropy_Lambda2': 0.01, 'MinCut': True,\n",
    "'MinCut_Lambda0': 0, 'MinCut_Lambda1': 0.1, 'MinCut_Lambda2': 0.1, 'F-test': False, 'Max_Pat_Entropy': False, 'Max_Pat_Entropy_Lambda0': 0.0001,\n",
    "'Max_Pat_Entropy_Lambda1': 0.1, 'Max_Pat_Entropy_Lambda2': 0.1, 'UnsupContrast': False, 'UnsupContrast_Lambda0': 0, 'UnsupContrast_Lambda1': 0,\n",
    "'UnsupContrast_Lambda2': 0, 'Lasso_Feat_Selection': False, 'Lasso_Feat_Selection_Lambda0': 0.1, 'SupervisedLearning_Lambda0': 1, \n",
    "'SupervisedLearning_Lambda1': 1, 'SupervisedLearning_Lambda2': 1, 'SupervisedLearning_Lambda3': 1, 'SupervisedLearning': True}\n",
    "\n",
    "params4 = {\"path\": \"/home/carol/NaroNet-main/NaroNet-main/EXP2/\", \"PCL_embedding_dimensions\": 256, \"PCL_batch_size\": 160, \"PCL_epochs\": 300, \"PCL_patch_size\": 32, \"PCL_alpha_L\": 1.3, \"PCL_ZscoreNormalization\": True, \"PCL_width_CNN\": 2,\n",
    "\"PCL_depth_CNN\": 50, \"experiment_Label\": [\"Response\"], \"num_samples_architecture_search\": 100, \"epochs\": 20, \"epoch\": 0, \"lr_decay_factor\": 0.5, \"lr_decay_step_size\": 12, \"weight_decay\": 0.01, \"batch_size\": 6, \"lr\": 0.001,\n",
    "\"useOptimizer\": \"ADAM\", \"context_size\": 15, \"num_classes\": 3, \"MultiClass_Classification\": 1, \"showHowNetworkIsTraining\": False, \"visualizeClusters\": True, \"learnSupvsdClust\": True, \"recalculate\": False, \"folds\": 13, \n",
    "\"device\": \"cuda\", \"normalizeFeats\": False, \"normalizeCells\": False, \"Batch_Normalization\": True, \"normalizePercentile\": False, \"dataAugmentationPerc\": 0.0001, \"hiddens\": 44, \"clusters1\": 10, \"clusters2\": 9, \"clusters3\": 7,\n",
    "\"LSTM\": False, \"GLORE\": False, \"Phenotypes\": True, \"DeepSimple\": False, \"isAttentionLayer\": False, \"ClusteringOrAttention\": True, \"1cell1cluster\": False, \"dropoutRate\": 0.2, \"AttntnSparsenss\": False, \"attntnThreshold\": 0,\n",
    "\"GraphConvolution\": \"ResNet\", \"n-hops\": 3, \"modeltype\": \"SAGE\", \"ObjectiveCluster\": True, \"ReadoutFunction\": False, \"NearestNeighborClassification\": False, \"NearestNeighborClassification_Lambda0\": 1,\n",
    "\"NearestNeighborClassification_Lambda1\": 1, \"NearestNeighborClassification_Lambda2\": 1, \"KinNearestNeighbors\": 5, \"pearsonCoeffSUP\": False, \"pearsonCoeffUNSUP\": False, \"orthoColor\": True, \"orthoColor_Lambda0\": 0.1,\n",
    "\"orthoColor_Lambda1\": 1e-05, \"ortho\": False, \"ortho_Lambda0\": 0.1, \"ortho_Lambda1\": 0, \"ortho_Lambda2\": 0, \"min_Cell_entropy\": True, \"min_Cell_entropy_Lambda0\": 1, \"min_Cell_entropy_Lambda1\": 0.0001,\n",
    "\"min_Cell_entropy_Lambda2\": 0.01, \"MinCut\": True, \"MinCut_Lambda0\": 0, \"MinCut_Lambda1\": 0.1, \"MinCut_Lambda2\": 0.1, \"F-test\": False, \"Max_Pat_Entropy\": False, \"Max_Pat_Entropy_Lambda0\": 0.0001,\n",
    "\"Max_Pat_Entropy_Lambda1\": 0.1, \"Max_Pat_Entropy_Lambda2\": 0.1, \"UnsupContrast\": False, \"UnsupContrast_Lambda0\": 0, \"UnsupContrast_Lambda1\": 0, \"UnsupContrast_Lambda2\": 0, \"Lasso_Feat_Selection\": False,\n",
    "\"Lasso_Feat_Selection_Lambda0\": 0.1, \"SupervisedLearning_Lambda0\": 1, \"SupervisedLearning_Lambda1\": 1, \"SupervisedLearning_Lambda2\": 1, \"SupervisedLearning_Lambda3\": 1, \"SupervisedLearning\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(params4 == params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'keys_only_in_dict1': set(), 'keys_only_in_dict2': set(), 'differing_values': {'showHowNetworkIsTraining': (False, True)}}\n"
     ]
    }
   ],
   "source": [
    "differences = compare_dicts(params4, params3)\n",
    "print(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dicts(dict1, dict2):\n",
    "    differences = {\n",
    "        'keys_only_in_dict1': set(dict1.keys()) - set(dict2.keys()),\n",
    "        'keys_only_in_dict2': set(dict2.keys()) - set(dict1.keys()),\n",
    "        'differing_values': {}\n",
    "    }\n",
    "\n",
    "    for key in dict1.keys() & dict2.keys():\n",
    "        if dict1[key] != dict2[key]:\n",
    "            differences['differing_values'][key] = (dict1[key], dict2[key])\n",
    "\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check generated graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of the loaded data: <class 'torch_geometric.data.data.Data'>\n",
      "Node feature matrix shape: torch.Size([33605, 262])\n",
      "Graph connectivity shape: torch.Size([2, 167253])\n",
      "Edge feature matrix shape: None\n",
      "Target shape: [0]\n"
     ]
    }
   ],
   "source": [
    "# Load the .pt file\n",
    "file_path = '/home/carol/NaroNet-main/NaroNet-main/Endometrial_POLE/NaroNet/POLE Mutation_Copy number variation_MSI Status_Tumour Type/Subject_graphs/data_0_0.pt'\n",
    "file_path = '/home/carol/NaroNet-main/NaroNet-main/Lung_cancer/NaroNet/Response/Subject_graphs/data_1_0.pt'\n",
    "loaded_data = torch.load(file_path)\n",
    "\n",
    "data_type = type(loaded_data)\n",
    "print(\"Type of the loaded data:\", data_type)\n",
    "\n",
    "# Assuming loaded_data is an instance of torch_geometric.data.Data\n",
    "print(\"Node feature matrix shape:\", loaded_data.x.shape if loaded_data.x is not None else \"Not present\")\n",
    "print(\"Graph connectivity shape:\", loaded_data.edge_index.shape if loaded_data.edge_index is not None else \"Not present\")\n",
    "print(\"Edge feature matrix shape:\", loaded_data.edge_attr)\n",
    "print(\"Target shape:\", loaded_data.y if loaded_data.y is not None else \"Not present\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature matrix shape: torch.Size([11625, 263])\n",
      "Graph connectivity shape: torch.Size([2, 57682])\n",
      "Edge feature matrix shape: None\n",
      "Target shape: ['Mutated', 'High', 'Stable', 'Endometria carcinoma ']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding eps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two NumPy arrays\n",
    "array1 = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "array2 = np.array([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "# Specify the file name\n",
    "filename = 'my_arrays.npz'\n",
    "\n",
    "# Save the arrays in a single file\n",
    "np.savez(filename, array1=array1, array2=array2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1.e+00 1.e-10 1.e+00 1.e+00 1.e+00 1.e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# Assuming denom is your array\n",
    "denom = np.array([[[1, 0, 1, 1, 1, 1]]])\n",
    "denom = denom.astype(np.float64)\n",
    "# Define a small value, epsilon\n",
    "epsilon = 1e-10\n",
    "\n",
    "# Add epsilon to only the zero elements\n",
    "denom[denom == 0] += epsilon\n",
    "\n",
    "# Now denom no longer contains any zero values\n",
    "print(denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "denom = np.array([[[1, 0, 1, 4, 2, 1]]])\n",
    "print(np.any(denom.tolist() == 0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m denom[denom \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mfloat_info\u001b[38;5;241m.\u001b[39mepsilon\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(denom)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: Cannot cast ufunc 'add' output from dtype('float64') to dtype('int64') with casting rule 'same_kind'"
     ]
    }
   ],
   "source": [
    "denom[denom == 0] += sys.float_info.epsilon\n",
    "print(denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check parameters dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {'path': '/home/carol/NaroNet-main/NaroNet-main/Lung_cancer/', 'PCL_embedding_dimensions': 256, 'PCL_batch_size': 160, 'PCL_epochs': 300, 'PCL_patch_size': 32,\n",
    "        'PCL_alpha_L': 1.3, 'PCL_ZscoreNormalization': True, 'PCL_width_CNN': 2, 'PCL_depth_CNN': 50, 'experiment_Label': ['Response'], 'num_samples_architecture_search': 50,\n",
    "        'epochs': 10, 'epoch': 0, 'lr_decay_factor': 0.5, 'lr_decay_step_size': 12, 'weight_decay': 0.01, 'batch_size': 6, 'lr': 0.001, 'useOptimizer': 'ADAM', 'context_size': 15,\n",
    "        'num_classes': 3, 'MultiClass_Classification': 1, 'showHowNetworkIsTraining': True, 'visualizeClusters': True, 'learnSupvsdClust': True, 'recalculate': False, 'folds': 13,\n",
    "        'device': 'cuda', 'normalizeFeats': False, 'normalizeCells': False, 'Batch_Normalization': True, 'normalizePercentile': False, 'dataAugmentationPerc': 0.0001, 'hiddens': 44,\n",
    "        'clusters1': 10, 'clusters2': 9, 'clusters3': 7, 'LSTM': False, 'GLORE': False, 'Phenotypes': True, 'DeepSimple': False, 'isAttentionLayer': False,\n",
    "        'ClusteringOrAttention': True, '1cell1cluster': False, 'dropoutRate': 0.2, 'AttntnSparsenss': False, 'attntnThreshold': 0, 'GraphConvolution': 'ResNet', 'n-hops': 3, \n",
    "        'modeltype': 'SAGE', 'ObjectiveCluster': True, 'ReadoutFunction': False, 'NearestNeighborClassification': False, 'NearestNeighborClassification_Lambda0': 1, \n",
    "        'NearestNeighborClassification_Lambda1': 1, 'NearestNeighborClassification_Lambda2': 1, 'KinNearestNeighbors': 5, 'pearsonCoeffSUP': False, 'pearsonCoeffUNSUP': False,\n",
    "        'orthoColor': True, 'orthoColor_Lambda0': 0.1, 'orthoColor_Lambda1': 1e-05, 'ortho': False, 'ortho_Lambda0': 0.1, 'ortho_Lambda1': 0, 'ortho_Lambda2': 0,\n",
    "        'min_Cell_entropy': True, 'min_Cell_entropy_Lambda0': 1, 'min_Cell_entropy_Lambda1': 0.0001, 'min_Cell_entropy_Lambda2': 0.01, 'MinCut': True,\n",
    "        'MinCut_Lambda0': 0, 'MinCut_Lambda1': 0.1, 'MinCut_Lambda2': 0.1, 'F-test': False, 'Max_Pat_Entropy': False, 'Max_Pat_Entropy_Lambda0': 0.0001,\n",
    "        'Max_Pat_Entropy_Lambda1': 0.1, 'Max_Pat_Entropy_Lambda2': 0.1, 'UnsupContrast': False, 'UnsupContrast_Lambda0': 0, 'UnsupContrast_Lambda1': 0,\n",
    "        'UnsupContrast_Lambda2': 0, 'Lasso_Feat_Selection': False, 'Lasso_Feat_Selection_Lambda0': 0.1, 'SupervisedLearning_Lambda0': 1, \n",
    "        'SupervisedLearning_Lambda1': 1, 'SupervisedLearning_Lambda2': 1, 'SupervisedLearning_Lambda3': 1, 'SupervisedLearning': True}\n",
    "\n",
    "dict2 = {\"path\": \"/home/carol/NaroNet-main/NaroNet-main/Lung_cancer/\", \"PCL_embedding_dimensions\": 256, \"PCL_batch_size\": 160, \"PCL_epochs\": 300, \"PCL_patch_size\": 32,\n",
    "        \"PCL_alpha_L\": 1.3, \"PCL_ZscoreNormalization\": True, \"PCL_width_CNN\": 2, \"PCL_depth_CNN\": 50, \"experiment_Label\": [\"Response\"], \"num_samples_architecture_search\": 50,\n",
    "        \"epochs\": 10, \"epoch\": 0, \"lr_decay_factor\": 0.5, \"lr_decay_step_size\": 12, \"weight_decay\": 0.01, \"batch_size\": 6, \"lr\": 0.001, \"useOptimizer\": \"ADAM\", \"context_size\": 15,\n",
    "        \"num_classes\": 3, \"MultiClass_Classification\": 1, \"showHowNetworkIsTraining\": True, \"visualizeClusters\": True, \"learnSupvsdClust\": True, \"recalculate\": False,\n",
    "        \"folds\": 13, \"device\": \"cuda\", \"normalizeFeats\": False, \"normalizeCells\": False, \"Batch_Normalization\": True, \"normalizePercentile\": False, \n",
    "        \"dataAugmentationPerc\": 0.0001, \"hiddens\": 44, \"clusters1\": 10, \"clusters2\": 9, \"clusters3\": 7, \"LSTM\": False, \"GLORE\": False, \"Phenotypes\": True,\n",
    "        \"DeepSimple\": False, \"isAttentionLayer\": False, \"ClusteringOrAttention\": True, \"1cell1cluster\": False, \"dropoutRate\": 0.2, \"AttntnSparsenss\": False, \n",
    "        \"attntnThreshold\": 0, \"GraphConvolution\": \"ResNet\", \"n-hops\": 3, \"modeltype\": \"SAGE\", \"ObjectiveCluster\": True, \"ReadoutFunction\": False,\n",
    "        \"NearestNeighborClassification\": False, \"NearestNeighborClassification_Lambda0\": 1, \"NearestNeighborClassification_Lambda1\": 1,\n",
    "        \"NearestNeighborClassification_Lambda2\": 1, \"KinNearestNeighbors\": 5, \"pearsonCoeffSUP\": False, \"pearsonCoeffUNSUP\": False, \"orthoColor\": True,\n",
    "        \"orthoColor_Lambda0\": 0.1, \"orthoColor_Lambda1\": 1e-05, \"ortho\": False, \"ortho_Lambda0\": 0.1, \"ortho_Lambda1\": 0, \"ortho_Lambda2\": 0, \"min_Cell_entropy\": True,\n",
    "        \"min_Cell_entropy_Lambda0\": 1, \"min_Cell_entropy_Lambda1\": 0.0001, \"min_Cell_entropy_Lambda2\": 0.01, \"MinCut\": True, \"MinCut_Lambda0\": 0,\n",
    "        \"MinCut_Lambda1\": 0.1, \"MinCut_Lambda2\": 0.1, \"F-test\": False, \"Max_Pat_Entropy\": False, \"Max_Pat_Entropy_Lambda0\": 0.0001, \"Max_Pat_Entropy_Lambda1\": 0.1,\n",
    "        \"Max_Pat_Entropy_Lambda2\": 0.1, \"UnsupContrast\": False, \"UnsupContrast_Lambda0\": 0, \"UnsupContrast_Lambda1\": 0, \"UnsupContrast_Lambda2\": 0, \n",
    "        \"Lasso_Feat_Selection\": False, \"Lasso_Feat_Selection_Lambda0\": 0.1, \"SupervisedLearning_Lambda0\": 1, \"SupervisedLearning_Lambda1\": 1,\n",
    "        \"SupervisedLearning_Lambda2\": 1, \"SupervisedLearning_Lambda3\": 1, \"SupervisedLearning\": True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict1.keys():\n",
    "    if dict1[key]!=dict2[key]:\n",
    "        print(str(key) + ' ' + str(dict1[key]) + ' ' + str(dict2[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(dict1==dict2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking number of patches  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9270, 264)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/carol/NaroNet-main/NaroNet-main/Lung_cancer/Patch_Contrastive_Learning/Image_Patch_Representation/h13_10873_tl1.npy\"\n",
    "print(np.shape(np.load(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h17_6794_tl2.npy(31000, 264)\n",
      "h17_6226_tl4.npy(32800, 264)\n",
      "h16_16787_tl2.npy(19580, 264)\n",
      "h17_6226_tl2.npy(32800, 264)\n",
      "h16_15119_tl1.npy(32480, 264)\n",
      "h16_11096_tl1.npy(24038, 264)\n",
      "h16_19144_tl2.npy(23800, 264)\n",
      "h16_15767_tl3.npy(36516, 264)\n",
      "h16_28421_tl2.npy(31416, 264)\n",
      "h16_19144_tl4.npy(24252, 264)\n",
      "h16_16787_tl1.npy(22784, 264)\n",
      "h16_7700_tl2.npy(35076, 264)\n",
      "h16_11096_tl5.npy(7636, 264)\n",
      "h16_11096_tl3.npy(31866, 264)\n",
      "h17_6794_tl1.npy(20800, 264)\n",
      "h16_12101_tl1.npy(33488, 264)\n",
      "h16_11096_tl2.npy(27813, 264)\n",
      "h16_15119_tl2.npy(24160, 264)\n",
      "h16_19144_tl1.npy(39720, 264)\n",
      "h17_6226_tl1.npy(32800, 264)\n",
      "h14_28759_tl2.npy(31020, 264)\n",
      "h16_28421_tl4.npy(31416, 264)\n",
      "h16_28421_tl3.npy(31416, 264)\n",
      "h13_10873_tl2.npy(33605, 264)\n",
      "h16_11096_tl4.npy(41514, 264)\n",
      "h16_15767_tl1.npy(33464, 264)\n",
      "h16_19144_tl3.npy(21109, 264)\n",
      "h16_28421_tl1.npy(31416, 264)\n",
      "h16_19144_tl7.npy(24252, 264)\n",
      "h16_12101_tl2.npy(22650, 264)\n",
      "h16_7700_tl1.npy(30336, 264)\n",
      "h16_15767_tl2.npy(30222, 264)\n",
      "h13_10873_tl1.npy(9270, 264)\n",
      "h16_9373_tl1.npy(33320, 264)\n",
      "h13_10873_tl3.npy(2950, 264)\n",
      "h16_19144_tl6.npy(24252, 264)\n",
      "h16_9373_tl2.npy(29750, 264)\n",
      "h17_6794_tl3.npy(36490, 264)\n",
      "h14_28759_tl1.npy(11392, 264)\n",
      "h17_6226_tl3.npy(32800, 264)\n",
      "h16_19144_tl5.npy(24252, 264)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/carol/NaroNet-main/NaroNet-main/Lung_cancer/Patch_Contrastive_Learning/Image_Patch_Representation\" \n",
    "for filename in os.listdir(path):\n",
    "    npar = np.load(path+'/'+filename)\n",
    "    print(filename + str(np.shape(npar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h16_12101_tl1.npy(70819, 136)\n",
      "h16_19144_tl7.npy(51324, 136)\n",
      "h16_9373_tl1.npy(70788, 136)\n"
     ]
    }
   ],
   "source": [
    "path = \"/home/carol/NaroNet-main/Datasets/PCL_outputs/Patch_Contrastive_Learning_ps22/Image_Patch_Representation\"\n",
    "for filename in os.listdir(path):\n",
    "    npar = np.load(path+'/'+filename)\n",
    "    print(filename + str(np.shape(npar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h17_6794_tl2.npy(31000, 264)\n",
      "h17_6226_tl4.npy(32800, 264)\n",
      "h16_16787_tl2.npy(19580, 264)\n",
      "h17_6226_tl2.npy(32800, 264)\n",
      "h16_11096_tl1.npy(24038, 264)\n",
      "h16_19144_tl2.npy(23800, 264)\n",
      "h16_28421_tl2.npy(31416, 264)\n",
      "h16_16787_tl1.npy(22784, 264)\n",
      "h16_7700_tl2.npy(35076, 264)\n",
      "h16_11096_tl3.npy(31866, 264)\n",
      "h16_11096_tl2.npy(27813, 264)\n",
      "h16_19144_tl1.npy(39720, 264)\n",
      "h16_28421_tl4.npy(31416, 264)\n",
      "h13_10873_tl2.npy(33605, 264)\n",
      "h16_28421_tl1.npy(31416, 264)\n",
      "h16_12101_tl2.npy(22650, 264)\n",
      "h16_7700_tl1.npy(30336, 264)\n",
      "h16_15767_tl2.npy(30222, 264)\n",
      "h16_9373_tl1.npy(33320, 264)\n",
      "h13_10873_tl3.npy(2950, 264)\n",
      "h16_19144_tl6.npy(24252, 264)\n",
      "h16_9373_tl2.npy(29750, 264)\n",
      "h17_6226_tl3.npy(32800, 264)\n",
      "h16_19144_tl5.npy(24252, 264)\n"
     ]
    }
   ],
   "source": [
    "#checking path array sizes for A.patch representations and B. preprocesed images\n",
    "\n",
    "path = \"/home/carol/NaroNet-main/Datasets/IPR/Image_Patch_Representation_ps22\"\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    npar = np.load(path+'/'+filename)\n",
    "    print(filename + str(np.shape(npar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33605, 264)\n",
      "(33605, 264)\n",
      "(33605, 264)\n"
     ]
    }
   ],
   "source": [
    "#comparing if image patch representation vectors are the same on two different iterations\n",
    "path1 = \"/home/carol/NaroNet-main/NaroNet-main/Lung_cancer/Patch_Contrastive_Learning/Image_Patch_Representation/h13_10873_tl2.npy\"\n",
    "path2 = \"/home/carol/NaroNet-main/Datasets/Image_Patch_Representation_ps22/h13_10873_tl2.npy\"\n",
    "path3 = \"/home/carol/NaroNet-main/Datasets/Image_Patch_Representation_ps22/run2_ps32/h13_10873_tl2.npy\"\n",
    "array1 = np.load(path1)\n",
    "array2 = np.load(path2)\n",
    "array3 = np.load(path3)\n",
    "print(np.shape(array1))\n",
    "print(np.shape(array2))\n",
    "print(np.shape(array3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7550, 4600, 6)\n"
     ]
    }
   ],
   "source": [
    "path4 = \"/home/carol/NaroNet-main/NaroNet-main/Lung_cancer/Patch_Contrastive_Learning/Preprocessed_Images/h13_10873_tl2.npy\"\n",
    "array4 = np.load(path4)\n",
    "print(np.shape(array4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decimal checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the arrays equal up to the second decimal?  False\n",
      "Are the arrays equal up to the third decimal?  False\n"
     ]
    }
   ],
   "source": [
    "rounded_arr1_2dp = np.around(array3, decimals=2)\n",
    "rounded_arr2_2dp = np.around(array2, decimals=2)\n",
    "are_equal_2dp = np.array_equal(rounded_arr1_2dp, rounded_arr2_2dp)\n",
    "\n",
    "# Compare for third decimal place\n",
    "rounded_arr1_3dp = np.around(array3, decimals=3)\n",
    "rounded_arr2_3dp = np.around(array2, decimals=3)\n",
    "are_equal_3dp = np.array_equal(rounded_arr1_3dp, rounded_arr2_3dp)\n",
    "\n",
    "# Output the results\n",
    "print(\"Are the arrays equal up to the second decimal? \", are_equal_2dp)\n",
    "print(\"Are the arrays equal up to the third decimal? \", are_equal_3dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are the arrays equal up to the second decimal?  False\n"
     ]
    }
   ],
   "source": [
    "# Compare for third decimal place\n",
    "rounded_arr1_4dp = np.around(array3, decimals=4)\n",
    "rounded_arr2_4dp = np.around(array2, decimals=4)\n",
    "are_equal_4dp = np.array_equal(rounded_arr1_3dp, rounded_arr2_3dp)\n",
    "print(\"Are the arrays equal up to the second decimal? \", are_equal_4dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences for second decimal place:  66269\n"
     ]
    }
   ],
   "source": [
    "differences_2dp = np.sum(rounded_arr1_2dp != rounded_arr2_2dp)\n",
    "print(\"Differences for second decimal place: \", differences_2dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences for second decimal place:  662834\n"
     ]
    }
   ],
   "source": [
    "differences_3dp = np.sum(rounded_arr1_3dp != rounded_arr2_3dp)\n",
    "print(\"Differences for second decimal place: \", differences_3dp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.60000000e+01  1.60000000e+01 -1.72941767e-01 -1.72943636e-01\n",
      " -1.72941865e-01 -1.72943731e-01 -1.72941915e-01 -1.72943788e-01\n",
      " -2.52729368e+00  1.60067332e+00 -4.81508851e-01 -6.12240434e-02\n",
      "  5.60304642e-01  7.08035290e-01  1.22876811e+00  1.63058090e+00\n",
      "  1.50733495e+00 -8.78988206e-02 -6.57963634e-01  2.96522677e-01\n",
      "  2.42388630e+00 -1.06474221e+00 -5.93141079e-01  9.74468529e-01\n",
      "  5.37092328e-01 -9.18477595e-01 -4.40133125e-01 -8.22815955e-01\n",
      "  7.55571604e-01 -5.67771673e-01  1.93880707e-01  1.62770963e+00\n",
      "  1.12464786e+00 -3.50794196e-01 -2.27988958e-01 -8.97854924e-01\n",
      " -9.25166607e-02 -6.99304819e-01  1.72314033e-01  1.33716881e+00\n",
      "  1.18558228e-01 -3.15756381e-01 -2.03897285e+00  1.43722379e+00\n",
      "  1.03845394e+00  4.47935820e-01  2.77847886e-01  4.48035896e-01\n",
      "  1.76331565e-01 -8.19253683e-01 -1.16527128e+00 -2.21640611e+00\n",
      "  5.63945413e-01  6.22443497e-01  9.02707696e-01 -7.73391604e-01\n",
      " -6.44636512e-01  7.25969732e-01 -7.84394622e-01 -1.39271450e+00\n",
      " -1.40775287e+00  2.01210594e+00  1.07503295e+00 -2.25083303e+00\n",
      "  7.61974692e-01  3.83523107e-01  1.44172227e+00 -4.08226401e-01\n",
      " -4.44268286e-01  2.27745056e+00 -2.24402905e-01  3.31086576e-01\n",
      " -3.61983538e-01 -1.85372138e+00  1.16798258e+00 -1.02590621e+00\n",
      " -2.75973582e+00 -1.54249668e+00 -1.16536355e+00 -9.66463089e-01\n",
      "  1.30733681e+00  5.72744548e-01  4.22765434e-01 -7.47361660e-01\n",
      "  1.25166440e+00 -5.89738846e-01  1.92579746e+00  1.25352335e+00\n",
      "  8.98005128e-01  1.39614034e+00 -7.46623218e-01 -4.72053379e-01\n",
      " -1.27756095e+00  5.82234442e-01 -2.81191140e-01  1.06023163e-01\n",
      " -8.33775282e-01  2.20033264e+00  5.55954337e-01  7.12671578e-01\n",
      "  1.66535318e-01 -8.03172350e-01 -1.23238266e+00  5.44889510e-01\n",
      "  1.07034993e+00 -6.64073288e-01  1.89266950e-01 -7.47406721e-01\n",
      " -1.23468232e+00  6.01596832e-02 -3.01610470e-01 -1.78109813e+00\n",
      " -1.31899416e-02 -3.78030807e-01 -6.68548107e-01 -4.71960485e-01\n",
      "  8.57358694e-01 -1.87809557e-01  7.26848423e-01 -1.46381259e-01\n",
      " -9.68339086e-01 -4.10109907e-01 -4.60262954e-01 -5.28017640e-01\n",
      "  1.59302443e-01  4.78438675e-01 -2.96840906e-01  6.69138193e-01\n",
      "  1.23200476e-01  1.05809999e+00 -3.46192092e-01  1.04653811e+00\n",
      " -1.73389032e-01 -1.12496281e+00 -1.49225175e-01 -1.32369280e-01\n",
      " -2.09519911e+00 -5.25195420e-01 -1.80544841e+00 -1.02082264e+00\n",
      "  8.16354930e-01  5.52596271e-01  7.73782134e-01 -1.75656304e-01\n",
      "  4.47271287e-01  1.07888710e+00  8.46707582e-01 -5.04415870e-01\n",
      " -2.49723768e+00 -9.56060112e-01  4.31750655e-01  1.27448902e-01\n",
      " -7.10549474e-01 -2.15543079e+00  1.89849281e+00  3.21451545e-01\n",
      " -7.58983433e-01  1.29676199e+00 -1.25405622e+00  2.26958692e-01\n",
      "  9.89158869e-01 -4.63155150e-01  7.71323204e-01  2.87242085e-01\n",
      " -2.41328970e-01 -2.60748172e+00 -1.26555276e+00 -3.45697343e-01\n",
      " -1.73736906e+00  5.60737908e-01 -7.31281191e-03  1.35579705e+00\n",
      " -4.56944168e-01 -1.49286115e+00 -4.10735846e-01  8.18830192e-01\n",
      " -9.10079658e-01 -1.73601761e-01  4.40216333e-01 -2.22461686e-01\n",
      "  3.04969519e-01  1.02581656e+00  7.13316381e-01 -5.96972585e-01\n",
      "  8.40776026e-01  5.75380743e-01  4.38690066e-01  1.42057943e+00\n",
      " -1.34530872e-01 -9.41357732e-01 -1.01124740e+00  1.40843773e+00\n",
      " -3.83177251e-01  6.74743176e-01  1.16018736e+00 -1.08787978e+00\n",
      " -1.93935251e+00  3.97267044e-01  1.17246354e+00 -1.05127728e+00\n",
      "  4.93866682e-01 -2.64346331e-01  4.40172315e-01  1.63687259e-01\n",
      " -6.11624837e-01 -4.54547465e-01 -7.60366917e-01 -2.72076666e-01\n",
      "  4.61316019e-01  4.34948057e-01 -2.16239524e+00 -7.94584155e-01\n",
      " -1.84576404e+00 -1.24337232e+00 -1.66338325e+00  6.12368226e-01\n",
      "  1.19149804e+00 -1.33856118e-01  7.28686333e-01  1.25431311e+00\n",
      " -5.12280345e-01 -1.54100680e+00 -4.24297094e-01 -6.29937291e-01\n",
      "  4.13510293e-01 -3.07050169e-01 -1.11981761e+00  3.68109554e-01\n",
      "  1.05337501e-01  1.18141985e+00 -1.68068349e-01 -3.32883894e-01\n",
      " -5.50672889e-01  2.88009882e+00 -1.45869994e+00 -3.97976935e-01\n",
      "  1.55788213e-01  4.14900684e+00  9.54484105e-01  1.12967014e-01\n",
      "  2.20667332e-01 -1.49437428e+00  4.48337853e-01 -4.88975719e-02\n",
      " -4.85341191e-01  3.65680516e-01 -5.15682578e-01  6.12078190e-01\n",
      " -6.86962008e-01  7.31243551e-01 -4.71015573e-01 -3.69584680e-01\n",
      " -5.06821871e-01  6.09186053e-01 -1.45884812e+00 -2.27407098e-01\n",
      "  8.32446814e-01 -2.21297860e-01 -3.23597670e-01  2.14946389e+00\n",
      " -4.38563883e-01  9.07213628e-01 -3.02405953e-01 -1.08774400e+00]\n"
     ]
    }
   ],
   "source": [
    "print(array3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.60000000e+01  1.60000000e+01 -1.72941767e-01 -1.72943636e-01\n",
      " -1.72941865e-01 -1.72943731e-01 -1.72941915e-01 -1.72943788e-01\n",
      " -2.52690983e+00  1.60044646e+00 -4.81510282e-01 -6.10085130e-02\n",
      "  5.60173512e-01  7.07803786e-01  1.22861016e+00  1.63035679e+00\n",
      "  1.50737119e+00 -8.79045427e-02 -6.58199191e-01  2.96498060e-01\n",
      "  2.42369556e+00 -1.06482673e+00 -5.93218923e-01  9.74289298e-01\n",
      "  5.37066281e-01 -9.17933762e-01 -4.40269023e-01 -8.22759807e-01\n",
      "  7.55840063e-01 -5.67345083e-01  1.94079846e-01  1.62742746e+00\n",
      "  1.12512815e+00 -3.50810617e-01 -2.27823615e-01 -8.98178339e-01\n",
      " -9.26491022e-02 -6.99446559e-01  1.72344878e-01  1.33732104e+00\n",
      "  1.18570805e-01 -3.15785468e-01 -2.03931022e+00  1.43711209e+00\n",
      "  1.03853202e+00  4.47996140e-01  2.77933061e-01  4.47711200e-01\n",
      "  1.76133856e-01 -8.19282413e-01 -1.16544974e+00 -2.21607351e+00\n",
      "  5.64109802e-01  6.22300565e-01  9.02819753e-01 -7.73557067e-01\n",
      " -6.44600213e-01  7.26174116e-01 -7.84283519e-01 -1.39259505e+00\n",
      " -1.40767920e+00  2.01170897e+00  1.07504773e+00 -2.25062323e+00\n",
      "  7.61954963e-01  3.83417726e-01  1.44170403e+00 -4.08343494e-01\n",
      " -4.44393516e-01  2.27705956e+00 -2.24149376e-01  3.31276298e-01\n",
      " -3.62321913e-01 -1.85361004e+00  1.16783845e+00 -1.02565920e+00\n",
      " -2.75941849e+00 -1.54224598e+00 -1.16551447e+00 -9.66483295e-01\n",
      "  1.30723441e+00  5.72466373e-01  4.23035800e-01 -7.47647285e-01\n",
      "  1.25202060e+00 -5.89639902e-01  1.92576957e+00  1.25339055e+00\n",
      "  8.97976995e-01  1.39600682e+00 -7.46575236e-01 -4.72176552e-01\n",
      " -1.27771962e+00  5.81944346e-01 -2.81257153e-01  1.05941415e-01\n",
      " -8.33631992e-01  2.20038867e+00  5.55930257e-01  7.12431431e-01\n",
      "  1.66452676e-01 -8.03252220e-01 -1.23200691e+00  5.45053244e-01\n",
      "  1.07011223e+00 -6.64031267e-01  1.88975066e-01 -7.47303128e-01\n",
      " -1.23496699e+00  5.95664978e-02 -3.01656365e-01 -1.78093266e+00\n",
      " -1.31498277e-02 -3.78008634e-01 -6.68223917e-01 -4.71779466e-01\n",
      "  8.57423067e-01 -1.87705159e-01  7.26888180e-01 -1.46150947e-01\n",
      " -9.68400598e-01 -4.10253137e-01 -4.60406065e-01 -5.27974725e-01\n",
      "  1.59605175e-01  4.78029847e-01 -2.96774268e-01  6.69169605e-01\n",
      "  1.23450935e-01  1.05807400e+00 -3.46344143e-01  1.04651904e+00\n",
      " -1.73162192e-01 -1.12466526e+00 -1.49399579e-01 -1.32465184e-01\n",
      " -2.09506726e+00 -5.25376320e-01 -1.80512798e+00 -1.02097034e+00\n",
      "  8.16122591e-01  5.52472293e-01  7.73649812e-01 -1.75753042e-01\n",
      "  4.47273374e-01  1.07889640e+00  8.46508026e-01 -5.04369497e-01\n",
      " -2.49678397e+00 -9.56307173e-01  4.31642681e-01  1.27987519e-01\n",
      " -7.10508108e-01 -2.15531063e+00  1.89839530e+00  3.21408451e-01\n",
      " -7.58926272e-01  1.29653215e+00 -1.25415480e+00  2.27006853e-01\n",
      "  9.89221275e-01 -4.63157117e-01  7.71262407e-01  2.87490547e-01\n",
      " -2.41172209e-01 -2.60739088e+00 -1.26547575e+00 -3.45866472e-01\n",
      " -1.73715520e+00  5.60658813e-01 -7.25871325e-03  1.35563898e+00\n",
      " -4.57029045e-01 -1.49288321e+00 -4.10652220e-01  8.18554342e-01\n",
      " -9.10013378e-01 -1.73673645e-01  4.40050632e-01 -2.22205356e-01\n",
      "  3.04936379e-01  1.02555263e+00  7.12995112e-01 -5.96831441e-01\n",
      "  8.40851724e-01  5.75311124e-01  4.38683510e-01  1.42023253e+00\n",
      " -1.34864122e-01 -9.41154778e-01 -1.01110518e+00  1.40834939e+00\n",
      " -3.83057654e-01  6.74741507e-01  1.16022074e+00 -1.08769953e+00\n",
      " -1.93923700e+00  3.97459745e-01  1.17249799e+00 -1.05103064e+00\n",
      "  4.94011760e-01 -2.64206260e-01  4.40206885e-01  1.64004266e-01\n",
      " -6.11574292e-01 -4.54272598e-01 -7.60187745e-01 -2.72049516e-01\n",
      "  4.61183339e-01  4.34828073e-01 -2.16216207e+00 -7.94863105e-01\n",
      " -1.84565926e+00 -1.24349546e+00 -1.66352391e+00  6.12392426e-01\n",
      "  1.19116914e+00 -1.33693725e-01  7.28724360e-01  1.25404119e+00\n",
      " -5.12037992e-01 -1.54085815e+00 -4.24498260e-01 -6.29969954e-01\n",
      "  4.13210481e-01 -3.06854784e-01 -1.11960661e+00  3.67962569e-01\n",
      "  1.05531156e-01  1.18125820e+00 -1.68158934e-01 -3.33461881e-01\n",
      " -5.50692558e-01  2.87973404e+00 -1.45887721e+00 -3.98118138e-01\n",
      "  1.55988574e-01  4.14873314e+00  9.54450250e-01  1.13069266e-01\n",
      "  2.20831126e-01 -1.49427080e+00  4.48212326e-01 -4.93057221e-02\n",
      " -4.84955490e-01  3.65805209e-01 -5.15763223e-01  6.11906290e-01\n",
      " -6.87099516e-01  7.31308103e-01 -4.71171975e-01 -3.69735837e-01\n",
      " -5.06852388e-01  6.08766675e-01 -1.45855844e+00 -2.27562547e-01\n",
      "  8.32165003e-01 -2.21190989e-01 -3.23596507e-01  2.14960790e+00\n",
      " -4.38545465e-01  9.07355309e-01 -3.02633405e-01 -1.08785343e+00]\n"
     ]
    }
   ],
   "source": [
    "print(array2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image embeddings should of size 128 according to paper.\n",
    "Check if all 264 positions are non-zero. \n",
    "Check what's the difference between patch rep and prep images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(image_data):\n",
    "    \n",
    "    print(\"Image shape:\", image_data.shape)\n",
    "\n",
    "    mean_value = np.mean(image_data)\n",
    "    std_value = np.std(image_data)\n",
    "    min_value = np.min(image_data)\n",
    "    max_value = np.max(image_data)\n",
    "\n",
    "    print(\"Mean:\", mean_value)\n",
    "    print(\"Standard Deviation:\", std_value)\n",
    "    print(\"Minimum:\", min_value)\n",
    "    print(\"Maximum:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (264,)\n",
      "Mean: 0.20679186495261342\n",
      "Standard Deviation: 3.20183238504033\n",
      "Minimum: -2.2506768703460693\n",
      "Maximum: 48.0\n"
     ]
    }
   ],
   "source": [
    "explore(npar[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anotherone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
